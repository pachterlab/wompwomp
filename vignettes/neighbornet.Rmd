---
title: "Introduction to alluvialmatch"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to alluvialmatch}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r}
devtools::load_all()
# library(alluvialmatch)
library(dplyr)
library(ggplot2)
library(ggalluvial)
library(ggforce)
library(igraph)
library(tibble)
```

We create a toy data frame that maps tissues (brain, stomach, heart, T cell, B cell) to clustering (1-4)
```{r}
df <- data.frame(
  tissue = c(
    1, 1, 1,
    2, 2, 2, 2, 2, 2,
    3, 3, 3, 3, 3, 3, 3,
    4, 4,
    5, 5, 5, 5, 5, 5, 5, 5, 5
  ),
  cluster = c(
    1, 1, 2,
    1, 2, 2, 2, 2, 2,
    1, 3, 3, 3, 3, 3, 3,
    4, 4,
    4, 4, 4, 4, 4, 4, 5, 5, 5
  )
)

# df <- data.frame(
#   tissue = c(
#     1, 1, 1,
#     2, 2, 2, 2, 2, 2,
#     3, 3, 3, 3, 3, 3, 3,
#     4, 4,
#     5, 5, 5, 5, 5, 5, 5, 5, 5
#   ),
#   cluster = c(
#     2, 2, 1,
#     2, 1, 1, 1, 1, 1,
#     2, 3, 3, 3, 3, 3, 3,
#     4, 4,
#     4, 4, 4, 4, 4, 4, 4, 4, 5
#   )
# )
column1 <- "tissue"
column2 <- "cluster"

head(df)
```


Neighbornet
```{r}
clus_df_gather <- df |>
    dplyr::mutate_if(is.numeric, function(x) factor(x, levels = as.character(sort(unique(x))))) |>
    dplyr::group_by_all() |>
    dplyr::count(name = "value")
gather_set_data(clus_df_gather, 1:2)

clus_df_gather
```

Optimal
```{r}
plot_alluvial(clus_df_gather, column1="tissue", column2="cluster", column_weights = "value", sorting_algorithm = "greedy_WBLF", color_bands=TRUE)
```

Without sorting - happens to already be optimal - so I expect each graph to be [1, 2, 3, 4, 5]
```{r}
plot_alluvial(clus_df_gather, column1="tissue", column2="cluster", column_weights = "value", sorting_algorithm = "None")
```


Build the bipartite graph
```{r}
library(igraph)

number_levels_col1 <- length(levels(clus_df_gather$tissue))
number_levels_col2 <- length(levels(clus_df_gather$cluster))

if (number_levels_col1 != number_levels_col2) {
    stop("Currently requires equal number of clusters on both sides for neighbornet")
}
number_clusters <- number_levels_col1

# Add prefixes to distinguish node types
clus_df_gather$tissue <- paste0("left_", clus_df_gather$tissue)
clus_df_gather$cluster <- paste0("right_", clus_df_gather$cluster)

# Build the graph
g <- graph_from_data_frame(clus_df_gather, directed = FALSE)

# Get all node names
all_nodes <- sort(unique(c(clus_df_gather$tissue, clus_df_gather$cluster)))

# Compute full distance matrix based on 1 / (edge weight)
# Initialize distance matrix
full_dist_matrix <- matrix(1e6, nrow = length(all_nodes), ncol = length(all_nodes),
                      dimnames = list(all_nodes, all_nodes))

# initialize all cross-nodes to 1000
n <- number_clusters
full_dist_matrix[1:n, (n+1):(2*n)] <- 1000
full_dist_matrix[(n+1):(2*n), 1:n] <- 1000

# Fill in distances based on 1 / weight
for (i in seq_len(nrow(clus_df_gather))) {
  n1 <- clus_df_gather$tissue[i]
  n2 <- as.character(clus_df_gather$cluster[i])  # ensure consistent type
  w  <- clus_df_gather$value[i]

  full_dist_matrix[n1, n2] <- 1 / w
  full_dist_matrix[n2, n1] <- 1 / w  # symmetric since graph is undirected
}



# Compute full distance matrix based on path distance - WRONG
# full_dist_matrix <- distances(g, v = all_nodes, to = all_nodes)
# # Set Inf for same-side nodes
# for (i in seq_along(all_nodes)) {
#   for (j in seq_along(all_nodes)) {
#     if ((startsWith(all_nodes[i], "left_") && startsWith(all_nodes[j], "left_")) ||
#         (startsWith(all_nodes[i], "right_") && startsWith(all_nodes[j], "right_"))) {
#       full_dist_matrix[i, j] <- Inf
#     }
#   }
# }
```

```{r}
full_dist_matrix
```


```{r}
conda_env <- "seurat_vs_scanpy"
Sys.setenv(RETICULATE_PYTHON = paste("/Users/joeyrich/miniconda3/envs", conda_env, "bin/python3.9", sep = "/"))
library(reticulate)
use_condaenv("/Users/joeyrich/miniconda3/envs/seurat_vs_scanpy/bin/python3.9", required = TRUE)
```

If I use SplitsTree:

#nexus

BEGIN DISTANCES;
DIMENSIONS ntax=10;
FORMAT labels=left diagonal triangle=Both;
MATRIX
[1] '1'     1000000 1000000 1000000 1000000 1000000 0.5 1 1000 1000 1000
[2] '2'     1000000 1000000 1000000 1000000 1000000 1 0.2 1000 1000 1000
[3] '3'     1000000 1000000 1000000 1000000 1000000 1 1000 0.17 1000 1000
[4] '4'     1000000 1000000 1000000 1000000 1000000 1000 1000 1000 0.5 1000
[5] '5'     1000000 1000000 1000000 1000000 1000000 1000 1000 1000 0.17 0.33
[6] '11'     0.5 1 1000 1000 1000 1000000 1000000 1000000 1000000 1000000
[7] '12'     1 0.2 1000 1000 1000 1000000 1000000 1000000 1000000 1000000
[8] '13'     1000 1000 0.17 1000 1000 1000000 1000000 1000000 1000000 1000000
[9] '14'     1000 1000 1000 0.5 0.17 1000000 1000000 1000000 1000000 1000000
[10] '15'     1000 1000 1000 1000 0.33 1000000 1000000 1000000 1000000 1000000
;
END; [DISTANCES]

From Tara Chari, from David J. Bryant and Daniel H. Huson
```{python}
from typing import Tuple
from splitspy.nnet import nnet_cycle, nnet_splits
import numpy as np

def neighbor_net(labels: [str], mat: [float], cutoff=0.0001, constrained=True) -> Tuple[list, list]:
    cycle = nnet_cycle.compute(labels, mat)

    splits = nnet_splits.compute(len(labels), mat, cycle, cutoff, constrained)

    return cycle, splits

labels = r.all_nodes
matrix = r.full_dist_matrix.copy()  # copy to avoid read-only
matrix[np.isinf(matrix)] = 1e6  # replace inf with 1e6 to avoid error
matrix = np.nan_to_num(matrix, nan=1e6)  # replace nan with 1e6 to avoid error
matrix = matrix.tolist()  # convert numpy matrix --> list of lists

cycle, splits = neighbor_net(labels, matrix)
```

Interpret this
```{python}
left_graph, right_graph = [], []

for i, node_index in enumerate(cycle):
    if node_index == 0:  # skip 0 (weird value)
        continue
    node = labels[node_index-1]
    if i % 2 != 0:
    # if node.startswith("left"):
        left_graph.append(node)
    else:
        right_graph.append(node)

print(left_graph)
print(right_graph)
```



```{r}
sessioninfo::session_info()
```
