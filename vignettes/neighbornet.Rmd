---
title: "Introduction to alluvialmatch"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to alluvialmatch}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r}
devtools::load_all()
# library(alluvialmatch)
library(dplyr)
library(ggplot2)
library(ggalluvial)
library(ggforce)
library(igraph)
library(tibble)
```

We create a toy data frame that maps tissues (brain, stomach, heart, T cell, B cell) to clustering (1-4)
```{r}
df <- data.frame(
  tissue = c(
    1, 1, 1,
    2, 2, 2, 2, 2, 2,
    3, 3, 3, 3, 3, 3, 3,
    4, 4,
    5, 5, 5, 5, 5, 5, 5, 5, 5
  ),
  cluster = c(
    1, 1, 2,
    1, 2, 2, 2, 2, 2,
    1, 3, 3, 3, 3, 3, 3,
    4, 4,
    4, 4, 4, 4, 4, 4, 5, 5, 5
  )
)

head(df)
```

Implementing a greedy heuristic for weighted one-layer free problem
```{r}
clus_df_gather_sorted <- greedy_wolf(df, column1="tissue", column2="cluster")
alluvialmatch_objective <- determine_crossing_edges(clus_df_gather_sorted, column1 = "tissue", column2 = "cluster", return_weighted_layer_free_objective = TRUE)
```

Neighbornet
```{r}
clus_df_gather <- df |>
    dplyr::mutate_if(is.numeric, function(x) factor(x, levels = as.character(sort(unique(x))))) |>
    dplyr::group_by_all() |>
    dplyr::count(name = "value")
gather_set_data(clus_df_gather, 1:2)

clus_df_gather
```
Build the bipartite graph
```{r}
library(igraph)

# Add prefixes to distinguish node types
clus_df_gather$tissue <- paste0("left_", clus_df_gather$tissue)
clus_df_gather$cluster <- paste0("right_", clus_df_gather$cluster)

# Build the graph
g <- graph_from_data_frame(clus_df_gather, directed = FALSE)

# Get all node names
all_nodes <- sort(unique(c(clus_df_gather$tissue, clus_df_gather$cluster)))

# Compute full distance matrix
full_dist_matrix <- distances(g, v = all_nodes, to = all_nodes)

# Set Inf for same-side nodes
for (i in seq_along(all_nodes)) {
  for (j in seq_along(all_nodes)) {
    if ((startsWith(all_nodes[i], "left_") && startsWith(all_nodes[j], "left_")) ||
        (startsWith(all_nodes[i], "right_") && startsWith(all_nodes[j], "right_"))) {
      full_dist_matrix[i, j] <- Inf
    }
  }
}
```

```{r}
conda_env <- "seurat_vs_scanpy"
Sys.setenv(RETICULATE_PYTHON = paste("/Users/joeyrich/miniconda3/envs", conda_env, "bin/python3.9", sep = "/"))
library(reticulate)
use_condaenv("/Users/joeyrich/miniconda3/envs/seurat_vs_scanpy/bin/python3.9", required = TRUE)
```


From Tara Chari, from David J. Bryant and Daniel H. Huson
```{python}
from typing import Tuple
from splitspy.nnet import nnet_cycle, nnet_splits
import numpy as np

def neighbor_net(labels: [str], mat: [float], cutoff=0.0001, constrained=True) -> Tuple[list, list]:
    cycle = nnet_cycle.compute(labels, mat)

    splits = nnet_splits.compute(len(labels), mat, cycle, cutoff, constrained)

    return cycle, splits

labels = r.all_nodes
matrix = r.full_dist_matrix.copy()  # copy to avoid read-only
matrix[np.isinf(matrix)] = 1e6  # replace inf with 1e6 to avoid error
matrix = np.nan_to_num(matrix, nan=1e6)  # replace nan with 1e6 to avoid error
matrix = matrix.tolist()  # convert numpy matrix --> list of lists

cycle, splits = neighbor_net(labels, matrix)
```

```{r}
sessioninfo::session_info()
```
